"Your Kindle Notes For:",,,
"SUPERFORECASTING: THE ART AND SCIENCE OF PREDICTION",,,
"by Philip E. Tetlock, Dan Gardner",,,
"Free Kindle instant preview:",,,
"http://amzn.to/2d6Q9Eb",,,
----------------------------------------------,,,
,,,
"Annotation Type","Location","Starred?","Annotation"
"Highlight (Yellow)","Page 1","","We are all forecasters. When we think about changing jobs, getting married, buying a home, making an investment, launching a product, or retiring, we decide based on how we expect the future will unfold. These expectations are forecasts."
"Highlight (Yellow)","Page 3","","talents. I call them superforecasters because that is what they are. Reliable evidence proves it. Explaining why they’re so good, and how others can learn to do what they do, is my goal in this book. How our low-profile"
"Highlight (Yellow)","Page 3","","Every day, the news media deliver forecasts without reporting, or even asking, how good the forecasters who made the forecasts really are. Every day, corporations and governments pay for forecasts that may be prescient or worthless or something in between. And every day, all of us—leaders of nations, corporate executives, investors, and voters—make critical decisions on the basis of forecasts whose quality is unknown."
"Highlight (Yellow)","Page 4","","for it turns out that forecasting is not a “you have it or you don’t” talent. It is a skill that can be cultivated. This book will show you how."
"Highlight (Yellow)","Page 5","","The one undeniable talent that talking heads have is their skill at telling a compelling story with conviction, and that is enough."
"Highlight (Yellow)","Page 5","","questions that only required looking one year out, and accuracy fell off the further out experts tried to forecast—approaching the dart-throwing-chimpanzee level three to five years out."
"Highlight (Yellow)","Page 6","","But debunkers go too far when they dismiss all forecasting as a fool’s errand. I believe it is possible to see into the future, at least in some situations and to some extent, and that any intelligent, open-minded, and hardworking person can cultivate the requisite skills. Call me an “optimistic skeptic.”"
"Highlight (Yellow)","Page 10","","In one of history’s great ironies, scientists today know vastly more than their colleagues a century ago, and possess vastly more data-crunching power, but they are much less confident in the prospects for perfect predictability."
"Highlight (Yellow)","Page 10","","But it is one thing to recognize the limits on predictability, and quite another to dismiss all prediction as an exercise in futility."
"Highlight (Yellow)","Page 13","Y","Unpredictability and predictability coexist uneasily in the intricately interlocking systems that make up our bodies, our societies, and the cosmos. How predictable something is depends on what we are trying to predict, how far into the future, and under what circumstances."
"Highlight (Yellow)","Page 14","Y","More often forecasts are made and then…nothing. Accuracy is seldom determined after the fact and is almost never done with sufficient regularity and rigor that conclusions can be drawn. The reason? Mostly it’s a demand-side problem: The consumers of forecasting—governments, business, and the public—don’t demand evidence of accuracy. So there is no measurement. Which means no revision. And without revision, there can be no improvement."
"Highlight (Yellow)","Page 15","","“I have been struck by how important measurement is to improving the human condition,” Bill Gates wrote. “You can achieve incredible progress if you set a clear goal and find a measure that will drive progress toward that goal….This may seem basic, but it is amazing how often it is not done and how hard it is to get right.”"
"Highlight (Yellow)","Page 18","Y","The other conclusion is what makes these superforecasters so good. It’s not really who they are. It is what they do. Foresight isn’t a mysterious gift bestowed at birth. It is the product of particular ways of thinking, of gathering information, of updating beliefs. These habits of thought can be learned and cultivated by any intelligent, thoughtful, determined person."
"Highlight (Yellow)","Page 20","","superforecasting demands thinking that is open-minded, careful, curious, and—above all—self-critical. It also demands focus. The kind of thinking that produces superior judgment does not come effortlessly. Only the determined can deliver it reasonably consistently, which is why our analyses have consistently found commitment to self-improvement to be the strongest predictor of performance."
"Highlight (Yellow)","Page 23","","we will need to blend computer-based forecasting and subjective judgment in the future. So it’s time we got serious about both."
"Highlight (Yellow)","Page 38","","The key is doubt. Scientists can feel just as strongly as anyone else that they know The Truth. But they know they must set that feeling aside and replace it with finely measured degrees of doubt—doubt that can be reduced (although never to zero) by better evidence from better studies."
"Highlight (Yellow)","Page 52","","That’s why forecasts without timelines don’t appear absurd when they are made. But as time passes, memories fade, and tacit time frames that once seemed obvious to all become less so. The result is often a tedious dispute about the “real” meaning of the forecast. Was the event expected this year or next? This decade or next? With no time frame, there is no way to resolve these arguments to everyone’s satisfaction—especially when reputations are on the line."
"Highlight (Yellow)","Page 54","","The key word in Kent’s work is estimate. As Kent wrote, “estimating is what you do when you do not know.”"
"Highlight (Yellow)","Page 57","","A more serious objection—then and now—is that expressing a probability estimate with a number may imply to the reader that it is an objective fact, not the subjective judgment it is. That is a danger. But the answer is not to do away with numbers. It’s to inform readers that numbers, just like words, only express estimates—opinions—and nothing more."
"Highlight (Yellow)","Page 58","","Only after the debacle over Saddam Hussein’s supposed weapons of mass destruction, and the wholesale reforms that followed, did it become more acceptable to express probabilities with numbers."
"Highlight (Yellow)","Page 64","","The math behind this system was developed by Glenn W. Brier in 1950, hence results are called Brier scores. In effect, Brier scores measure the distance between what you forecast and what actually happened."
"Highlight (Yellow)","Page 65","","For example, after the 2012 presidential election, Nate Silver, Princeton’s Sam Wang, and other poll aggregators were hailed for correctly predicting all fifty state outcomes, but almost no one noted that a crude, across-the-board prediction of “no change”—if a state went Democratic or Republican in 2008, it will do the same in 2012—would have scored forty-eight out of fifty, which suggests that the many excited exclamations of “He called all fifty states!” we heard at the time were a tad overwrought."
"Highlight (Yellow)","Page 68","","If you didn’t know the punch line of EPJ before you read this book, you do now: the average expert was roughly as accurate as a dart-throwing chimpanzee."
"Highlight (Yellow)","Page 68","","So why did one group do better than the other? It wasn’t whether they had PhDs or access to classified information. Nor was it what they thought—whether they were liberals or conservatives, optimists or pessimists. The critical factor was how they thought."
"Highlight (Yellow)","Page 69","","Foxes beat hedgehogs. And the foxes didn’t just win by acting like chickens, playing it safe with 60% and 70% forecasts where hedgehogs boldly went with 90% and 100%. Foxes beat hedgehogs on both calibration and resolution. Foxes had real foresight. Hedgehogs didn’t."
"Highlight (Yellow)","Page 72","","That too is consistent with the EPJ data, which revealed an inverse correlation between fame and accuracy: the more famous an expert was, the less accurate he was."
"Highlight (Yellow)","Page 73","","Aggregating the judgment of many consistently beats the accuracy of the average member of the group, and is often as startlingly accurate as Galton’s weight-guessers. The"
"Highlight (Yellow)","Page 74","","Now look at how foxes approach forecasting. They deploy not one analytical idea but many and seek out information not from one source but many. Then they synthesize it all into a single conclusion. In a word, they aggregate. They may be individuals working alone, but what they do is, in principle, no different from what Galton’s crowd did. They integrate perspectives and the information contained within them. The only real difference is that the process occurs within one skull."
"Highlight (Yellow)","Page 87","","It’s sensible stuff, but the point of making forecasts is not to tick all the boxes on the “how to make forecasts” checklist. It is to foresee what’s coming. To have accountability for process but not accuracy is like ensuring that physicians wash their hands, examine the patient, and consider all the symptoms, but never checking to see whether the treatment works."
"Highlight (Yellow)","Page 111","","What Fermi understood is that by breaking down the question, we can better separate the knowable and the unknowable. So guessing—pulling a number out of the black box—isn’t eliminated. But we have brought our guessing process out into the light of day where we can inspect it. And the net result tends to be a more accurate estimate than whatever number happened to pop out of the black box when we first read the question."
"Highlight (Yellow)","Page 120","Y","So a forecaster who starts by diving into the inside view risks being swayed by a number that may have little or no meaning. But if she starts with the outside view, her analysis will begin with an anchor that is meaningful. And a better anchor is a distinct advantage."
"Highlight (Yellow)","Page 123","","Researchers have found that merely asking people to assume their initial judgment is wrong, to seriously consider why that might be, and then make another judgment, produces a second estimate which, when combined with the first, improves accuracy almost as much as getting a second estimate from another person."
"Highlight (Yellow)","Page 126","","A brilliant puzzle solver may have the raw material for forecasting, but if he doesn’t also have an appetite for questioning basic, emotionally charged beliefs he will often be at a disadvantage relative to a less intelligent person who has a greater capacity for self-critical thinking. It’s not the raw crunching power you have that matters most. It’s what you do with it."
"Highlight (Yellow)","Page 127","Y","For superforecasters, beliefs are hypotheses to be tested, not treasures to be guarded."
"Highlight (Yellow)","Page 129","","I have yet to find a superforecaster who isn’t comfortable with numbers and most are more than capable of putting them to practical use. And"
"Highlight (Yellow)","Page 144","","Aleatory uncertainty ensures life will always have surprises, regardless of how carefully we plan. Superforecasters grasp this deep truth better than most. When they sense that a question is loaded with irreducible uncertainty—say, a currency-market question—they have learned to be cautious, keeping their initial estimates inside the shades-of-maybe zone between 35% and 65% and moving out tentatively. They know the “cloudier” the outlook, the harder it is to beat that dart-throwing chimpanzee."
"Highlight (Yellow)","Page 153","","Superforecasting isn’t a paint-by-numbers method but superforecasters often tackle questions in a roughly similar way—one that any of us can follow: Unpack the question into components. Distinguish as sharply as you can between the known and unknown and leave no assumptions unscrutinized. Adopt the outside view and put the problem into a comparative perspective that downplays its uniqueness and treats it as a special case of a wider class of phenomena. Then adopt the inside view that plays up the uniqueness of the problem. Also explore the similarities and differences between your views and those of others—and pay special attention to prediction markets and other methods of extracting wisdom from crowds. Synthesize all these different views into a single vision as acute as that of a dragonfly. Finally, express your judgment as precisely as you can, using a finely grained scale of probability."
"Highlight (Yellow)","Page 172","","Minto is a Bayesian who does not use Bayes’ theorem. That paradoxical description applies to most superforecasters."
"Highlight (Yellow)","Page 181","","To learn from failure, we must know when we fail."
"Highlight (Yellow)","Page 185","","To get better at a certain type of forecasting, that is the type of forecasting you must do—over and over again, with good feedback telling you how your training is going, and a cheerful willingness to say, “Wow, I got that one wrong. I’d better think about why.”"
"Highlight (Yellow)","Page 190","","Computer programmers have a wonderful term for a program that is not intended to be released in a final version but will instead be used, analyzed, and improved without end. It is “perpetual beta.” Superforecasters are perpetual beta."
"Highlight (Yellow)","Page 191","","In philosophic outlook, they tend to be: CAUTIOUS: Nothing is certain HUMBLE: Reality is infinitely complex NONDETERMINISTIC: What happens is not meant to be and does not have to happen In their abilities and thinking styles, they tend to be: ACTIVELY OPEN-MINDED: Beliefs are hypotheses to be tested, not treasures to be protected INTELLIGENT AND KNOWLEDGEABLE, WITH A “NEED FOR COGNITION”: Intellectually curious, enjoy puzzles and mental challenges REFLECTIVE: Introspective and self-critical NUMERATE: Comfortable with numbers In their methods of forecasting they tend to be: PRAGMATIC: Not wedded to any idea or agenda ANALYTICAL: Capable of stepping back from the tip-of-your-nose perspective and considering other views DRAGONFLY-EYED: Value diverse views and synthesize them into their own PROBABILISTIC: Judge using many grades of maybe THOUGHTFUL UPDATERS: When facts change, they change their minds GOOD INTUITIVE PSYCHOLOGISTS: Aware of the value of checking thinking for cognitive and emotional biases In their work ethic, they tend to have: A GROWTH MINDSET: Believe it’s possible to get better GRIT: Determined to keep at it however long it takes"
"Highlight (Yellow)","Page 192","","paint with a broad brush here. Not every attribute is equally important. The strongest predictor of rising into the ranks of superforecasters is perpetual beta, the degree to which one is committed to belief updating and self-improvement. It is roughly three times as powerful a predictor as its closest rival, intelligence."
"Highlight (Yellow)","Page 199","","We also gave teams a primer on teamwork based on insights gleaned from research in group dynamics. On the one hand, we warned, groupthink is a danger. Be cooperative but not deferential. Consensus is not always good; disagreement not always bad. If you do happen to agree, don’t take that agreement—in itself—as proof that you are right. Never stop doubting. Pointed questions are as essential to a team as vitamins are to a human body."
"Highlight (Yellow)","Page 217","","Auftragstaktik blended strategic coherence and decentralized decision making with a simple principle: commanders were to tell subordinates what their goal is but not how to achieve it."
"Highlight (Yellow)","Page 228","","The humility required for good judgment is not self-doubt—the sense that you are untalented, unintelligent, or unworthy. It is intellectual humility. It is a recognition that reality is profoundly complex, that seeing things clearly is a constant struggle, when it can be done at all, and that human judgment must therefore be riddled with mistakes."
"Highlight (Yellow)","Page 231","","What makes them so good is less what they are than what they do—the hard work of research, the careful thought and self-criticism, the gathering and synthesizing of other perspectives, the granular judgments and relentless updating."
"Highlight (Yellow)","Page 236","","It suggests that the superforecasters not only paid attention to the time frame in the question but also thought about other possible time frames—and thereby shook off a hard-to-shake bias."
"Highlight (Yellow)","Page 239","","the great powers—also fail the unimaginability test. If black swans must be inconceivable before they happen, a rare species of event suddenly becomes a lot rarer. But Taleb also offers a more modest definition of a black swan as a “highly improbable consequential event.”6"
"Highlight (Yellow)","Page 239","","So the first-generation IARPA tournament tells us nothing about how good superforecasters are at spotting gray or black swans. They may be as clueless as anyone else—or astonishingly adept. We don’t know, and shouldn’t fool ourselves that we do."
"Highlight (Yellow)","Page 240","","Now if you believe that only black swans matter in the long run, the Good Judgment Project should only interest short-term thinkers. But history is not just about black swans. Look at the inch-worm advance in life expectancy. Or consider that an average of 1% annual global economic growth in the nineteenth century and 2% in the twentieth turned the squalor of the eighteenth century and all the centuries that preceded it into the unprecedented wealth of the twenty-first.7 History does sometimes jump. But it also crawls, and slow, incremental change can be profoundly important."
"Highlight (Yellow)","Page 243","","Taleb, Kahneman, and I agree there is no evidence that geopolitical or economic forecasters can predict anything ten years out beyond the excruciatingly obvious—“there will be conflicts”—and the odd lucky hits that are inevitable whenever lots of forecasters make lots of forecasts."
"Highlight (Yellow)","Page 244","","If you have to plan for a future beyond the forecasting horizon, plan for surprise. That means, as Danzig advises, planning for adaptability and resilience. Imagine a scenario in which reality gives you a smack in the ear and consider how you would respond. Then assume reality will give you a kick in the shin and think about dealing with that. “Plans are useless,” Eisenhower said about preparing for battle, “but planning is indispensable.”11"
"Highlight (Yellow)","Page 245","","Probability judgments should be explicit so we can consider whether they are as accurate as they can be. And if they are nothing but a guess, because that’s the best we can do, we should say so. Knowing what we don’t know is better than thinking we know what we don"
"Highlight (Yellow)","Page 248","","Some find it hard wrapping their heads around Taleb’s idea of statistical distributions of possible worlds. It feels like eggheaded nonsense. There is only one reality: what happened in the past, what we’re living in now, and what will happen in the future. But if you are as mathematically inclined as Taleb, you get used to the idea that the world we live in is but one that emerged, quasi-randomly, from a vast population of once-possible worlds. The past did not have to unfold as it did, the present did not have to be what it is, and the future is wide open. History is a virtually infinite array of possibilities."
"Highlight (Yellow)","Page 263","","Seen that way, it’s obvious that the big question is composed of many small questions. One is “Will North Korea test a rocket?” If it does, it will escalate the conflict a little. If it doesn’t, it could cool things down a little. That one tiny question doesn’t nail down the big question, but it does contribute a little insight. And if we ask many tiny-but-pertinent questions, we can close in on an answer for the big question."
"Highlight (Yellow)","Page 263","","In future research, I want to develop the concept and see how effectively we can answer unscorable “big questions” with clusters of little ones."
"Highlight (Yellow)","Page 268","","When a debate like “Keynesians versus Austerians” emerges, key figures could work together—with the help of trusted third parties—to identify what they disagree about and which forecasts would meaningfully test those disagreements."
"Highlight (Yellow)","Page 270","","(1) Triage"
"Highlight (Yellow)","Page 270","","(2) Break seemingly intractable problems into tractable sub-problems."
"Highlight (Yellow)","Page 270","","(3) Strike the right balance between inside and outside views."
"Highlight (Yellow)","Page 270","","(4) Strike the right balance between under- and overreacting to evidence"
"Highlight (Yellow)","Page 270","","(5) Look for the clashing causal forces at work in each problem"
"Highlight (Yellow)","Page 270","","(6) Strive to distinguish as many degrees of doubt as the problem permits but no more"
"Highlight (Yellow)","Page 270","","(7) Strike the right balance between under- and overconfidence, between prudence and decisiveness."
"Highlight (Yellow)","Page 270","","(8) Look for the errors behind your mistakes but beware of rearview-mirror hindsight biases"
"Highlight (Yellow)","Page 270","","(9) Bring out the best in others and let others bring out the best in you."
"Highlight (Yellow)","Page 270","","(10) Master the error-balancing bicycle."
"Highlight (Yellow)","Page 270","","(11) Don’t treat commandments as commandments"
"Highlight (Yellow)","Page 270","","The true explanation for why superforecasters outperformed intelligence analysts is unknown. But I doubt it is because superforecasters are smarter or more open-minded. I suspect they did better because they treat forecasting as a cultivatable skill whereas analysts work inside an organization that treats prediction as a sideshow, not part of the analyst’s real job."
